%%=========================================
%\addcontentsline{toc}{section}{Sammendrag \& konklusjoner}
\section*{Sammendrag og konklusjoner}
Dette prosjektet har hatt som mål å utforske ulike brukergrensesnitt i smarte hjem. Spesielt har fokuset vært på å utforske \emph{intelligente brukergrensesnitt}; alternative interaksjonsmetoder som kan ha økt effektivitet og som oppleves som naturlige. Dette ble utfordret gjennom å spørre hva slags programvare man ønsker i smarte hjem. Basert på logisk argumentasjon og empiriske bevis fra to studier, viste jeg at brukere av smarte hjem ønsker å lære om hjemmets tilstand, og de ønsker å utøve styring over hjemmet. Samtidig må privatliv og personvern beskyttes. Med dette utgangspunktet utforsket jeg hvordan gester og tale kan benyttes for å gi kommandoer, og hvordan informasjonen om hjemmets tilstand best mulig kan presenteres. Dersom brukere er interessert i å lære om hjemmets tilstand bør det designes informasjonsprogramvare; programvare som prioriterer data, framfor interaksjon. Det ble fokusert på å vise så mye informasjon på en så optimal måte som mulig, gjennom teknikker fra grafisk design. Regler for hvordan å vise den mest essensielle informasjonen ble utforsket og implementert i et grafisk brukergrensesnitt, som forandrer seg dynamisk basert på kontinuerlige datastrømmer fra det smarte hjemmet.

Jeg har vist at maskinlæring kan benyttes for å gi enkle sensorer en mer detaljert forståelse av abstrakte gester, enn det som eksplisitt kan programmeres. På bakgrunn av teknologiske og sikkerhetsmessige grunner har jeg vist at begrenset talegjenkjenning er mer aktuelt enn en forståelse av naturlig tale i hjemmet. Jeg har vist at begrenset talegjenkjenning og maskinlærte gester i kombinasjon, er en aktuell, multimodal måte å styre hjemmet på. Til sist har jeg vist hvordan et tradisjonelt brukergrensesnitt kan forbedres ved å designe rundt presentasjon av kontekstinformasjonen, framfor brukerinteraksjon.